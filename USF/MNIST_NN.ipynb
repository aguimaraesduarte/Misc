{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks for MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJztvX2MrNtV3vns7vrq0+ecezX25JqEibBxIKAIi1xCYgUH\nR45E4pEMKBHEQcMYNBoxJlGElAQhkdiBZFCIsDwBHBFBIGgAiQSiwMj4EhjsjPnyxBkyGAZbEBtD\nzL34+56Prq6u7j1/VK+6q1avtfeu6qp+q6qfn7T17nfX136rz3lqvWuvtXbKOYMQQkg3HHQ9AUII\nuc1QhAkhpEMowoQQ0iEUYUII6RCKMCGEdAhFmBBCOoQiTAghHUIRJoSQDqEIE0JIh/S6nkBK6UUA\nvgzAhwCMu50NIYSshRGAzwLwTM7546UnbkyEU0rfCODvAHgJgP8M4G/lnP9v56lfBuBHNjUPQgjp\nkK8B8KOlJ2zEHZFS+moA3wXgTQC+EDMRfial9GLn6R/axBwIIWQL+FDtCZvyCX8TgO/LOf9wzvm3\nAHwDgMcAvt55Ll0QhJB9papvaxfhlFIfwNMAfl7G8qxU288BeOW6P48QQnaZTVjCLwZwCOA5M/4c\nZv5hQgghlzBEjRBCOmQTIvwxAOcAnjLjTwF4dgOfRwghO8vaRTjnfAbgvQBeI2MppXR5/kvr/jxC\nCNllNhUn/BYAP5RSei+A92AWLXEHwA9t6PMIIWQn2YgI55x//DIm+Nswc0P8GoAvyzl/dBOfRwgh\nu0rqeqPPlNKfxsx9QQgh+8bTOef/VHoCoyMIIaRDKMKEENIhFGFCCOkQijAhhHQIRZgQQjqEIkwI\nIR1CESaEkA6hCBNCSIdQhAkhpEMowoQQ0iEUYUII6RCKMCGEdAhFmBBCOoQiTAghHUIRJoSQDqEI\nE0JIh1CECSGkQyjChBDSIRRhQgjpEIowIYR0CEWYEEI6hCJMCCEdQhEmhJAOoQgTQkiHUIQJIaRD\nKMKEENIhFGFCCOkQijAhhHQIRZgQQjqEIkwIIR1CESaEkA6hCBNCSIdQhAkhpEMowoQQ0iEUYUII\n6RCKMCGEdAhFmBBCOoQiTAghHdLregKE7CIpJfcYjS37vi2P5ZzDox0rzVkfveso9ZfFm1fpOlqO\nuw5FmOwskRhcRyRaOTg4mIuW7nvnrXNaRthTSri4uFhoOefwXOZ0cHBQ7XvXELUW7I+DzKt0jB7z\nxnYdijDZOUpW2bosthqHh4dz4bLNPlaavx2zVqkVcn1+fn7e1GS+0mSO0ZieuxZo79wjslBFRM/P\nzxeO3ljL8fz8HCmlnbeIKcJkp2i1Ejc9B0/Ier2eK27enKLzkkVt23Q6xdnZGabT6ZUm4/K+Mr+W\npkW5dtRYMbTn+odhOp0W+95xOp3i4OAA0+l0/v7a9bKrUITJTtAiupFvcxNzqYmaFuWab1WPaWvT\nCrEdm0wmODs7mx91X38HFxcX6PV66Pf7Tc3Ov/RDI5/h+XjtuYip/uGo9eW6RPi1AB8cHMwt/V2G\nIky2mprf17tdL71uHYgVKMJmBU6f93q9K/Op/Xi0uANEhE9PT3F6ejrva+sbmAmwFtDBYHClDYfD\nhXMrxKVm3QGl/vn5ufuDYftyPplM5vOQHxZ5L3FJ3IT/f9OsXYRTSm8C8CYz/Fs5589f92eR/Sby\nnS7jN90E2hUhwtbv9xdETPpahFss+MjP7LXxeIzxeIx+v39FgOU2XaxP/cMwHA7nbTQaXelHPyZe\nX4twLeJhOp3OxVV+OLzz09PT+edMJpP5j468j/ywRD7pXWNTlvD7ALwGgPxPmG7oc8ieUhPR0mr9\npoXYWsIibNqqlKMIVclloo96YazWPzk5WbBaPUtR+2/1j8NoNMJoNMLR0dGVo8xbnq+Ptq+/41oo\n2dnZGcbj8dx6l2bH7I+Kd13i76YlHDPNOX90Q+9NbiH2dr6lbQoRQ7kl17f1Yk3KcTAYLMw56mtX\nRBSxYKMXtABbsdL+V2u1y/yOjo5w584d3LlzZ94/OjpacE9YV4Vt1idcilmeTCZz6308HuPk5GTh\nXMbke9X+cB2iNp1OaQk38CdSSv8VwBjALwP4lpzz723os8ieUYokKLkobkqIPUtYW5fayhShiqx0\nO1+7EBY1EWGxgPUi3Pn5+dy3KmJmrXYtwsfHxzg+Pp739Q+Idl14Y1qEa0kjk8kEJycnePz4MU5O\nTq40+VEpWfbiWtE+8l1nEyL8KwDeAOD9AD4DwJsB/IeU0p/KOT/awOeRW0hJeDf9n9PzCWu/6tHR\n0byJUNXcJlqEdQSCjUaIohMALAiV+Ffta7UlLFbw8fEx7t69O2/yI+JZ9vYx6xMu9U9PT/H48eMr\nTfzQLQIsi3b2x2eXWbsI55yfUafvSym9B8DvAvgqAD+47s8j62OVf9DRa5YZb7V8PaGNsr82+R+0\n1+vNRdbeytsxbS3WLHYr7qX+wcHBQnacjqX1ogz0j4T+odCWsIiw+If180siDCzG7HoZcjlnDAaD\nKz+QWmR1rLDM3Ytf3vTf96bZeIhazvnTKaUPAHj5pj+LLFISs9rzS4/X/Jur9r3PsWOtWWqbtIYP\nDw/dBS3vOBwOF6615JrQ1xJlt+lrtb5oSWzQ6b2CtXZFeMUNIfPVrggbrmYt71I6sm0XFxcLPw76\nB8KGqukxnYBir23XkzSEjYtwSukugM8G8MOb/izyAiWh80TOvi56z5aaAtFzaq8tzdGzFmv9TYpw\n7TZdi1kkul6/9KNix8QXPRwOcXZ2NrckIxEWIbbiq5sOWbMibH/c5P1rdSDkaEU4EmQbM6wz6uT6\n9iVbDthMnPA/BfDTmLkg/hiAf4hZiNqPrfuziE90+xuNRa+3Y61uAC/RoNSPRNjre4tUkd90kyJs\nF6iicy9ErXStrd9dSmlurWpL8fz8fEGc5L2120EEWEdGWEtYxwTbCAzrgqgVD5JWEmFPlK0VrH9g\n9qFwj7AJS/gzAfwogBcB+CiAdwP4cznnj2/gs0hAzVotCbEdq7kCWt0D0WOlW3Tb11lcNqPLnm9S\nhHXMrdd0PK3+DmtW/zJ3D/IZ9nZdC7B830dHRwsREPpohViSTDwR1mFh2h1hC/F4zfNZ19wTnjti\nn6xgYDMLc69f93uS1Yj+M3vCZ1/nnS9T2MVzD0Tug5KlbsdFAEUcSv1NibC4AlrrMHjfc4v7pTQG\nYB5uZsVXP1eLsLZ+S5awhL5pAfb+VtoSbqmOVhPf6JzuCLKTeALsHfXza/3WGNaau8CLea25TaRF\n9Rq8tkkR1ha3Fn+vlb7X6LtuIXJByBz1969D0qKoDhFh/ffykkRSSlcW3bTo2nKTcq5FtUWMtQDb\nhTn7o7PLUIT3EE/MrG+xZA1HYmFFdZljaaxlsU+LcCmtVj92eLhYanGd329rHK/MoXS3YR+rpf/q\nkC8rSPqOQVq/378Sv6ybFeKSK0nP1Qpxra6xJ76lSnCeJczoCLJTeP7F0n+q2m1zVK5x2WYtx5II\n28e0+NpKYHZ8kyJs/dtauDyft/ce3nkU4hWFfXkCrC11m82nxdYepdk7psiNFfmCvbrBJV9wSZSt\nP9hzvew6FOE9pSTAdpGl5p+UvhZdzxdrx+x4VI2r9h9e93VYlj3asU2JMBDX/fWiGKK/j0frlj6e\nAFsXhBbh4XB4RWy9NhwOF+Zd+pEuuSN08khNhK3w1hbm6BMmW0+LK0L+w9rnl45WYL3Shqs06x7x\nLDHpl0ox2rZJEbbfcalfew/BC+uyAueFaOnvSLsgBoPBXNBaYprlaF0O+mjHSgKshdgr1B4JcWlh\nzv4g7QMU4T1CC4D+D9myIGZfL0fdLwmp9sWWxj1/bmRVemM2HtcKiB7fpAi3knOeL2QBmPf1mCZa\n2LLvKe+lf1C1dajvKiSu2YbQ2Ww4b+FNPi/KhouE1hvT5SptQfpSokYpOmIfoAjvEC0Wq/huW8K4\nbPhU1Jdj5GKIxkpWsh6PXA+eIGu/r76Wmg+2K6zYepalRsTO3oZ7+8gts1WQFXYbkXB6ejr/gZN5\ntKQjl+Zm23g8xqNHjxaaVFCTUpYizJEQ0x1BOsMTyWghywpVtPODDuOq3VaLuLeGZpWE34r2Mgtz\nNjrCWnItboCbZBmRsFEGJT9qaZNPr0VFfvr9/lyApUWLgN6553qI+uPx2K2iJiJsLWNmzJGtpGY1\nHhwcuHVgo7qwQJylZse8qIhlMtiisdKPir1WubW2VrUV4m0hcjtEaEvYq6mgfaeRtez1rQBPJpPQ\njaTn4aUmR2Fp3ufpo5SyFOvX1hUej8dh8R7PL7wPVjBAEd4ZPEGyK/HiGyythtsaAZHgeq0WD1uK\nmfX6cow+z5uLLDpZ69r6NLdFiJcVCi1uWjDtlkCnp6cLwlTry3uVIlbkWBNeawl7n+uNyVZGWnTt\n7hraEvbek3HCpFM8q9eGnMntughtlCF1586deT3YViH2sqhazmvj0ed687DZatvujljGEi4JsN0G\naDweV5MjdJMfvbOzs2qcd0uInLWEW5I17PZGVny1O0JXhbOfsW9CTBHeEUriq48iwmIJS+EWW0FL\nji2uAPvZNhmhdF5LZhAR1tcofW9MRNizsLdxYW4ZAZajrrWgRdhuB2TFz0sVtiLs/QjacS/+1xPk\nUqqyN5fIoo9EOKpHsU+LcgBFeKfQYhhZljo4XyxhXdD73r17874W4ZbUYRuB4GXfeVl5tcfk2lqO\n+pq972EXLWFPgK3/VkRYL2hFxXK8vvd9RUcvXjkasyLpzUGOZ2dnC+Fp0Xb34u8uxUzviwADFOGd\nIBJEz6KxGVIiwvfu3cO9e/dw//79ef/u3buur7m0MLZsv2VMrlFfb2ksEvNd9AnbxyNLWCzGx48f\nz8O7SiJlW+sP4sHBQSh6yySSeOfT6dTNjvP60+k0dIFYP/WuQxHeIbz/PDZN1fMJi+V7//59PPHE\nE/PjvXv3qiJcEmaZU6m1PkeeZ683+g5qPxC7gCcgniVs3RGeCEfuAumX/qb23HM3LCP4JaFuqR8h\ni3FeqJxt+wBFeEeIfLNWgEuW8P3793H//n08+eSTePLJJ3H//v1qyJu1WGUu+tg6Vnu+d82l78K+\nT8t7bguegGhfrA1Rs+6Ihw8fFqMWPGux5TtLKVWt3JKLoHTekl0n4xcXFwvf0zIJL7sGRXiH8KxU\nzyq2fmFPjJ944gk88cQTRbeBdSHsGuv4Txq9x3WEPhJgOerwLu2OEBF+9OgRHj58WLQQr7OA1SLC\nXh0HK77eY7VYYunvi8C2QBHeIbz/aN5/DC+u0rNa5D3EDyhCay2nXcdaTvro+WRL7yFE1mRk/bd8\njv6beotzNlyt5XZ9HSLcYv2WrHDpl+J9983FsAwU4R0isnisENsVaivG+nVagLU4iW9Q+rvKMiLl\n3fJG5y0+c/2dtrzvMiJ8cnJy5cek5bpaKLkUSlZvyRIv/Xu0bpPbBkV4R7D/4ayI2n/grX48AHOx\n2CfxFUqWmSce8hr9ejsGLNYTjvr6+7Rzivr2TkYvWNnYWjvn6HxZcSu5E0rfX2TZ6sdrSRe3UYgp\nwjtEJMQpJZyfn88XVUoxm571Yds+iC8Qf1+RRWefb99DjpE/Xl7nhd3p94j6Vqxa3RHenL3+Mt9b\nJMStghuJcM09dhuhCO8Y3j9suf31LOGaRazRVvB1LKltwhMA78cpsiS9voiwThrJOS/UL5bv0lrC\npb61hHW1MxsvfHJy4s7NHlf525WEtia++vV2PPIl79O/t1WgCO8AJcvC+iFbXRL69fb99uk/grXk\norTaVkERer3e/Lv0isdrF4+8j56TN6Z/LFot4dL72bFlvrNlm36dfQ97ffZIS5jsFFYwtRADuCI0\nJTGW9wGuWsHyWbtOZAl7xWFaBUe+dyl2o78n+VuIv17m4B3t2LLW8DICv+r3VvtB8v69lI4lP/Kq\nc911KMI7RGQJa7dCLTLCc0dEbgj5zF3F/ue3bhodo9pyi2xF2H5XNutsGYHS81zGHeG9h/cdrPq9\n2eOy1+O9vibstw2K8I4QCYL169ZihK1VqNNUtf9yX/5T2O/KipzeeaLVB+qJrF6sq6361yzFVneE\nfV973df5zqK5RmO181ZB34d/c8tCEd5BPPEVSlavJzTanbGPFklJgLXQWZdEqW9D+rwMxmWsRitC\nLdawtoRbvoN1fI/LvG/Lj8M6rPZ9gCK8Q3i3clqMc86uv7PUgBesuNpt+KZYJiRumXnULGAdgyuL\nc97CkRVjfcegM+N0uFrJGo6O3jwjd8Tp6Wnz90C2G4rwjmBvg2VMjmKh6VtZb2cGqT8wHA6vbDNU\n2oJIRwC0+AGXqdq16vcRzUf6UnvBa3ardalX0CLEBwf+Zqpe3+5oXTqen58vzCvaaZjsFxThHcRa\nYzVLSkTn5ORkvsmnbDVf2oTTnnuWcTSmrUJ9tGOriHDL5+ecQwvSO48W5yJL2NvJ2jvq3aRrtZUv\nLi5cEfYiOMj+QBHeIbSVqf8jil9XXAoXFxeuJXxycnJFHGrb1XsiXAozkmbLbGqrOuc8txBXrc7m\nuUvsPOwPkL4bsJtMSvnEmk9YRFg2G9W7FXt9uwlpqS8ifHp6ulBb11s4JPsDRXgHif4T2pV1K8L2\nNlmLcG0XXr0BZCngXo72Pfr9/jy2FsDKAhwJrzcHvTWQ7Eqht1rXW65PJpPqD4xnCZfaYDC4shlp\naUdqAFVLmO6I/YMivGPUrKBIhEWI+/3+3AIDsLB9vBYQ77wWcaHPtW/UFmuxtRaWdUnYBbdoPtYS\nll0p9BZB0hcRbrH0tSUcNf39eXcX3jnwggh7O03QEt5PKMI7gl2Nt/8RRRysCGtrUN8ay/vULDm5\nHe73+8VNHO3YcDjEcDi8IiAppbnldx2rzoqkNxd7J6B3pXj48OG8OPrDhw9xenpadW/ohbmWHy3v\n+4zGptMpUkoLOw7rRTmK8P5CEd4xPL+wtiZtoL+IkPVNyuvtQpIVBi3GUd0Fb8zuFSZzPjw8xHQ6\nnbs3Vv0OrCXszUOXfxQfsAjvgwcP5scHDx7g9PTUFV1PkMUS9lwu3pjcEciiqG5nZ2fz/uHhYRgd\nYa18sj9QhHeQ6D+hCIQWoclksuB31AJ8cXFxJaxKC8N0Op27E7QI24QHb8wTYO2DXtW/6Ymj96Og\nr1+H5okb4uHDh3j++efnTZeGLImxfMfWpeC5HUSE5a5A2mg0cu8UtAhbV4S2hMl+QRHeIbTFW3JH\n2OgILcDy3JxniR1ioWkfpHZDWIH19gaL9gsTkdWlH0XwtUCv+l1E1rB8vhcdIu6IBw8e4Pnnn8en\nP/1pfOpTnypuFxT5hGtRJSLCsvO1tMlkgtFodMXf2+v1muKEKcT7BUV4xyj9B5THtE9YuyDkOdpn\nOhwOMZlM5rfKIshWXGvNPk9EVguwCNNwOLyWf7NkBevPtwtzepNMLcCf+tSn5tsF1axgbQlHzVrD\nR0dHC81GPshn9vv9BZ+wzuajT3h/oQjvOPY/pF2Ysz5gL4xNhFduj211MREALc7Sj8Z07LIWYCs+\nq15zyRIWAbYhatYnLEL8yU9+ci7CLU1E2Caz2HZ4eIjBYIA7d+4sCKsVXwBzN5LnjtB3JBTg/YMi\nvId4YmsX5eR5pVt6EYHBYLCwWm9F12tRIoi3cCUxsjaV2Ras13P2qoxpl8rZ2dk8DlhnxtVu83XT\nn2fHJUrCfnc63E4E27qEvO///Pwc/X4fDx48mIfOnZycLERKUIj3E4rwHuLdroswWpHwnmeL28ji\nXeSa8MZFhD1r0S5i2R+I0jGy5r36EBIbLJawzUSzt/ien710+2+/P7FmNSklnJ2dzf299gdF/PcS\nMaLjl2Xe+oeDCRv7B0V4D2kR4Oh5siinb+d1yFptMU6OrZawvnWP0nkBLGTXRQJs60JYS7hWk0G+\nk0iQ7bl1i0RJJ+Kbtzug2B++Xq83j2W2lrD2DdMS3i8ownuIvc09ODjAdDp1H7dCILHB/X5/LsCn\np6cLlnApTG0VERaXRJTKCyC8hRch1pXibJqytoQjv6wVYdu336+diyfA8jy9MArE6eW9Xm9uvdsf\nD20JU4T3C4rwnqKFKvIBi3D2er0FN4S2UEUcer2eG4sbJW20uCHkKHOwNSr0opWudxxlBepQNFsb\nIoq/9URYH1vGZE7R8z0XhJ6/ruehfzAidwRFeL+gCO8ZVqisnzISYRHiaMVf0oy9zDSvv4wlLItS\nUuTn4mJWe8KKr70GETK79Y8IcLQwZyMOrDtCf07rd+09JnPXY3bhU+445DvWtY71ke6I/WVpEU4p\nvQrA3wXwNIDPAPAVOeefMs/5NgD/E4AnAfwigP8l5/zb158uacEKsTcm1qr4Ij1XgF5YOzw8XIgk\n0ILrjVkxL6X32pRciSrQfmEtkt4iYiTCdoGr5o6Qz7D9yC2hoyT09+xtnmotYP0D1+vNqtrZCA9r\nvXNhbv9YxRI+BvBrAH4AwE/aB1NK3wzgbwL4WgAfAvCPADyTUvq8nPNk9amSVrzbY73rhi2sLgtH\ntsnjuuCODcmyY9Iii9oTYet+AF7wo8q8vdt/HQ/s7R7iWcKeO0ILqP7Oat+xoH3CIr5623svXND7\njsV3X0uKoSW8XywtwjnndwB4BwAkfzn4bwP49pzz/3H5nK8F8ByArwDw46tPlbSihUr3dajXdDqd\nF9Rp2QVDi6EVXG9Mi3CtVrHMWbCV1qy1auOZa+4I7RP2CuOUQtFKgmcfE/ePjXU+ODiY//iVmriO\nIlePdZ2Q/WCtPuGU0ksBvATAz8tYzvn5lNKvAnglKMI3gl6xF4vMS3ywOwRrkfbGtbDXjjpLzoqx\nFDsXq9hunKmtQ3FXWHeExNfahTm9KNcSHVHyCde+Y923+8XpfrS3XikZpfb9kv1h3QtzLwGQMbN8\nNc9dPkZuiMiyA64Khbf3mde3VqO1tj0RjuopaBEWrPjabDZ9XXaBy5astP7g1uiIVb5nfYwoFa73\n4rejzyH7B6MjbiH2P7S2lMV/rH2bYk1bAS61yE1hfcqeX9m+l0b/KOhmfc66WptefNQuFm2B3vR3\n3voY2X/WLcLPAkgAnsKiNfwUgP9nzZ9FNkQkCsuIsH6fZV4XvZfGKwwkoit1eo+Ojq78EOgFLrG4\nb1KICfFYqwjnnD+YUnoWwGsA/L8AkFK6D+DPAvjedX4WWR/L+EFL4lh670iQW6xfPaYtYS3CeveK\n0Wi0sOimXReykGdLfBLSFavECR8DeDlmFi8AvCyl9AoAn8g5/x6AtwL41pTSb2MWovbtAH4fwL9b\ny4zJWtGLSnbcG7OWbktUgff8yJdsn+uhIze0G0IXp7ep1F5s7k27JAjxWMUS/iIAv4DZAlwG8F2X\n4/8KwNfnnL8zpXQHwPdhlqzxfwH4K5kxwluPFj0dsaAfi4QysmB1v7aoV3Jp6HlFlrCuiWzD2GyN\nBoow2RZWiRN+F4DiPVzO+c0A3rzalEgXaIu4tojkuRhqz68t4NV8yoIXwmZ3h9bxtTqMLaraJu/L\nBTLSBYyOIAtEroWSZewda5+xrBBrPCGWSAgddiYZdZKkobP1vIU5CjHpAoowuSKykRh5Imz79vmr\nREKUfM2RO8LbMkiL8Onp6UK1smhhjkJMbhqKMAHguyO0IJX8va3nre6IaH7ymF2Yk1rHtgDQ+fn5\nXICHw+EVKzjyCVOIyU1CESZzSgtzteeXnuNZuC0Lc54we5awlMLUz5P6GJJFJyFs1hKOFuYoxOSm\noAgTl3UIUORD9sS41SIGrqY323oKukjReDzGcDicC7BnDRPSJRRhshG0wNrNQ8VFIJEK2r1gox7k\nKPUeAFzx/VrLWMYmk8lcgLUl7LXpdHrlh0L6doyQdUIRJhtBBNjuozYej+fCa10BuqKYtXZFjFNK\n7iKclL/UQqlFVwux17ydl621LtdFyDqhCJONEImwDQ3z3AjaqrWxwFKbV4um3gZJNgdNKV2xgEsi\nLJawVyNZ5kghJpuAIkw2QiTCXn1irzKatxvHYDBY2KlC7x4ir9f9FgtYi7Ct8GYryHGxjmwCijDZ\nCJ4IWxeECF7NBSFiKpa057PV9Y9FjCVLrsUatpl2EuKmr4cCTDYBRZhsBE+ErQDLYwCuLMzZhbPh\ncDiv+yBE/mSh1QrWIizbPtmwNVtzmZB1QREmG0MLrQ4F08V1RJxLFvBwOJwnXGgfsN0eyI55FnBk\nDUsER7TVkN5RmZB1QhEmG0FbwtqClJoOIsAS8WB9wFogpVD7ZDIrxGc3IPV22pA44WUW5qwFbOOY\nWW2NbAKKMNkIWoTtea/Xm9f2lUgJK8DWCpb94eS5gi6+4+1R17I4J+UvrRUs4mstbELWCUWYbAQt\nulbQxD2hrVm7N5zeJUM28ZxMJtVNSsWfLCLc6hMWK9tav3INzKwjm4IiTDaCTnCQW3lxTVjh1CKs\n3Q/D4RDj8Rij0WhejtK+1kZHaItaRNha11GTeWsRFgGmFUw2BUWYbASd4KB9whJ3q2/vdSqz3rZ+\nOBzOjyKielHPS1uOUpml5rC2sEejEe7cuYPJZIKc80LRd11fwp5LRIe+ztp565HcPijC5MaIhEZH\nUWgxPjk5uVL1TMLdhsPhghiLoItQ2nRmvQ+d7Mas96I7PDycf7ZY3dG5iLBXIc7r63RonY3HlGgC\nUITJDaAF0Y4BuBJPLDUmrAADmIeSeWnL4o4Qi1k+U48PBgOMRqN5QSAR8V6v5wqvFeHJZLKwk3Ot\nWd+ydy7fAUX4dkIRJhtFRFL6Hp4l7NX9BXClbgSAK4tynqvC7shsRTwSYW9Mi3DLUa5N7wBts/IY\ng3x7oQiTG8GKsc48E6HSpS7H4/GCAGtB86qnRdsc2cfFEta1J2RhsCTC1h2hLVrb7MKeWO+62VA4\nLvrdXijCZGNosS2l+9qaw6enp80CbF0N2krVzzk8PLxSshLAwmMlX7BuZ2dnV9wLpb78uOj6Gfo7\nogjfbijC5EYoCbJ1R+gNOLUAi/hpP7C4IAaDwYKfV0dg2L3otADLeEl0PRHWbhHrZrBjUnjIhrpJ\n9qAVZnKUoSnZAAAgAElEQVS7oAiTjVJyQ1grVyxFzwIWKznnvJAZZxfbvIgJEVsr4DqmWNKilxXh\nyN+rCwLpaxLkuiTkjSJ8e6EIk41TW5yzhX4iAT49PZ0XbtcCLKnNNUvYuiD01knii24R4MlkckVo\nS31r2ev6Gba4Ebl9UITJjaDF1wqyFttIgCeTCfr9PgAsJF/Y2hLWJ6xD1+RcBFiXsCyJsH1MPkf7\nsb3FN13CU67XLtjZ6A9y+6AIkxvHWsNeoR9ZrNOFfkRItQtiNBrh6OhoQRx1/K1YwtYqthEN4o+u\nCbCMyWdpAbZj8lp9XdoCjvbaI7cLijDpHB0h4Imx9p32+32cnJzM29HREcbjsdts4oQgYqxrT4gg\n2h2fpZC8rnHsia131AuNVmSjRA49z5YUZyZ47D4UYbIVeJlmnoWoXQe6zsTjx48Xakz0ej0Mh8OF\nUpf6/by+dl3Y/evs4/KDUHNJnJ2dzUVdi7yue2wLEtkU52hMvjf9HXp9st1QhMnWYAXYi5/V4qaF\n+PHjxwsCfHh4iNFo5BZ71zs666Lwh4eHc5ET/zNwdRfolgU57c/WoqtdI97OIKUkENvkO5OjF4tN\nMd5+KMKkc7ziN9oS1ULiCfDJyckVAT44OJi7EsS1YI/AC4uEWiQ1VrSt0EahaXr3ECv+WtStRW5j\njKNz+91pAa4lx5DtgiJMtgZ72+097omwJ8BSIlP7cnUDXohTtkXhBWsBy64gNYG0omzFVx/lcwDM\nq8RZa1q/jy2j6fm85TGyG1CEyVZgBVhvrKkf80Q4KvZzdnY2D2OTlGUbK6yTN3QSiRZlLbAtaco2\nDM2zhCPftOdPlvc4OzsLv6/ad0u2F4ow2RqsAGtxikQ4EuCcM87OzjAajRZKVsr72QQOG8qm45VF\nrFsK9nihb1Z8bRPEepd2eHhYrDehvy9PjCm+uwFFmHSOFzeshVBbqlaEIwHWRYEiARbfqn5/G6Xg\nRShYESwd7Qainvhq5NrsbtJyXTreWPuAvbsH+oV3A4ow2So836YWEwkP04tungBrf6oWYAkxGwwG\nVzLranG5dvGw1OS9pW6wtYSj69YV5CIBljA3EVx790AB3i0owmQriMQXWNyRQ2fRnZ6eLohbTYBt\nurIu6CNC6RGJphVlry8ibN0O9rrlKAJrX6OvTSqvafTdgxZgivH2QxEmW0NLiJWNvdVCpSMSpNIZ\ncFWAbY0Ja6nKa0oJHt68vXPrjqhde1Ty0qY8WxHWPyaeGJPthSJMtpJIPLTI2lt86zMFXrAsberx\nYDDA6enp/Ghjd/URwJXFNcC3kO2Y+J7FP11a3Is+R74PuwCoozZ0jLF9HcV4u6EIk53Diq1OitDi\nJeUua77j8/NzjEYjN7XY65es5MiS1j8EEjan44vlNV5iSdS8eGJtKeukDrnmWp/cPBRhslNYi9DG\n4urnHRwcNInwdDrFaDRaED9p+lwLo/Yja7GNkjD0LiBSRN4KsC6zWRJfaVE5TUnq0Ndqj551TDHu\nBoow2Tm0gIrgeLG0Egnhia+tVzwajeaCrTPr7LlkzXkpyNp1IZ8FwLWEdf0HbS23Nkne0DHF1k2j\nrzdaPNTfF+kGijDZOayQ6mwy/Zi1TPXj4sKQuNzRaDRPfx4MBgtNxs7Pz+cCqgsA6ew7QYRYW8hi\nCWtR1CKuLWBrDXuuEV3jWBI7omvV4XP2u/SiNcjNQREmO4UWExv+ZcUZWNzFQ14jFqMI8Hg8xmg0\nwnA4XGjiu9WuAx2rq2N2Be2K0CKri8nbuGW91ZJ1hdiFRT2mXS1etIj+LqLEE1vDmNw8S4twSulV\nAP4ugKcBfAaAr8g5/5R6/AcB/I/mZe/IOb/2OhMlRBDxSKlcBF4/Xx6PSmHKLh226cUzfTuvBdWK\nmPW36iSRaFy7P0ouCN20W8T6w21MsXVFaFeIfh25eVaxhI8B/BqAHwDwk8FzfgbAGwDIX/h0hc8h\n5ApWROyYdlFYi68mwEdHR8WtkoAXROvi4mIuqlZYxULWY9Zlof3EUhx+MBhccXGUmvVNCzamWGfX\nyXdh63NQgLtjaRHOOb8DwDsAIMUR6Kc5549eZ2KERHiFakRYRIBFDEsCrF0Oo9Hoyoah1gIW4dSW\npYyL0Npbfi2o8lztgrBlL2vWb6kim5fUIe+hvyv5Dpldtx1syif86pTScwA+CeD/BPCtOedPbOiz\nyC1Ci4ic25RdaSKiWoB1koYsuPX7/dAC9vy3JRHWFrh+XEdOiGVqkzU8ES4JsvV3WwHWm6QK0XdF\nAe6OTYjwzwD4CQAfBPDZAL4DwNtTSq/M/CuTNSD/jHR2mL4pk77dZqjf78/LX+rws16vh/F43CTA\nVtRs9IMWVZ0FJ8+xvln9PL3QF4mvPvcWHeV6bXx09D22pFSTzbJ2Ec45/7g6/Y2U0q8D+B0Arwbw\nC+v+PHI7sQkIHp47otfrzS1EnYBxdna2IIg2AcNmzOkFOyu6XvacoBM47Ji3yKefY+ekX2N94jpV\nWupoiLtEHtffpbXuyc2x8RC1nPMHU0ofA/ByUITJDeOFZNkaCymleXlMCVnzFr3k9eLW0E38y16M\nsZfY4fVlLlrwxVrX1rlnTQvej4b8yHi7QWuhtr52cjNsXIRTSp8J4EUA/mDTn0WIxgvL0mFtGkn4\nqBWKPz8/x2QyqQqwjPX7/aYMOM/S1UWHbKEf8eFa69u6LkSExd8tC5Ny1NEeFOFuWCVO+Bgzq1bu\nsV6WUnoFgE9ctjdh5hN+9vJ5/wTABwA8s44JE7IM1gq2rgJ5zsHBQVOheBFqLbxWhO25l4gh59Zv\nbC1hL8NOW87AVQH2kjwkIkR+ZKRynFyfuC+4QHfzrGIJfxFmboV82b7rcvxfAXgjgC8A8LUAngTw\nEczE9x/knM+uvhUhm8UKsBcbK+JmC8XLYzbNuSTCOuzNS32WY7Srh5yLJWwtVC3SeixyQ8gipN0Q\n1V6fV6OY3AyrxAm/C0Dpr/WXV58OIeunlOAhVnBKCZPJpCrAk8nkitC2HIfDIabTKYbD4ZVi8iK0\nIo460kKsZc9KLomvrZ8sAmyvT8cTM0qiG1g7guw11h0RPSZiVhPgZURXJ4JIhIIVYBFNz7crGXZW\naEVgPWHWj2vruyTAUnmNlnA3UITJ3iICZlN1tfDKY3Iur/ME2FZYi0RXjw2HwysCDGBBUKOYZH1u\nRVtHXUQuCD3fyAWhEzqYtNENFGGy12hBsam62kesEya0APf7/fmCnU7w8CqtRVZwyQKWEplWhAVt\nBdutjTzr2G7hNB6PMRgMQgG20SDk5qEIk73HLsDp+GAdoqUtYBEmHTGhIxY84fXOJ5NJUYD1hqMy\nJx0zLI+Ja8KW09ShbLpovG6TyWR+/VaAJXqDPuHuoAiTvcbeWmuxE0TsdLF28ZN6acO9Xi8UXTs+\nmUyuuCDEStVp0nZeIro6M06O0vd8wGK5y+dLUSItwDoppSW9mWwWijC5FURirBHfq94uyR4llE2E\nTCxN3SSEbTKZzGNvRXxFgCNf8TK1HLSrIoqIkPl5JTx1+JxXFJ7cDBRhQi6xi3PWVyyWoq6/oDca\n9ZJAUkoLFqlOH5bX21RkAE1iGGXJ2cW+nPNcbO3ioredk7bMvTRpPU9yfSjChCisENvH5ChCbAVY\npxNLSJws0OnUYV2tzdtiSM+jhA1fk/fr9Rb/a5eE14rzdDp1a27YWhUU4vVAESbEEImLjq7QEQri\nctAhb3qfO0kXFneFtoIjEZZ5lITY1prQscX2/azQlqxiex06kkT/uFCE1wNFmJCAkhjrHTz0820Y\nGQCMx+MFd4S2hO1OyFZ0S0LsuSK8oj4pJbfCW9T0QqX8UOgfH0/kyepQhAlRaHGJEhesyNpxadPp\nFAAWrGDrE7aW8CpCbDPsZFyOBwcHoQXsWcMAFsRXl/2UiA2K8PqgCBNyiecPtkIsImRF2LohpB5D\nznnBEo62ULKfsezCnLyHLYspVnJJfK0QA7NIERFfiRgpWexkdSjChBhsZIQdt5XYrADr2OKc84JP\n2IuOaFmYi4RPi60d0xZyTXx1H8CCn1tfp/YJk/VAESZEoQW4JMTS15ahTiXWIjwejxesYIkP1u4I\n+97eucUTYABzS12nOreIr/RtZqEVYBsJQq4HRZgQQyTAGh0pYJM5tDheXFwULWFvy6JlbvX1Z2lh\nlB8Aef9WK1iKyEcC7MVDk+tBESbEoSTAWii9o+57ImyjI6IQNftZFhnXPmHd120Zd4RNztACzKy6\n9UMRJqSBKGqi5XY8El8bnqY/yxM6K/7ej4E3r5zzQjpz1Jemfxi0n1sv1FGI1wdFmOw9tlhPacxa\nst659z7RcTAY4IknnsC9e/dw9+5d3LlzB0dHRxiNRgsVzOzCWq1vrVXd98693ZXlR0HXTLYukyix\nhL7g9UERJntNi6haP671sXpjUbPvOxgMcP/+fdy/f38uwqPR6MpuzN6PQw3P7RA1K7xWjKOmrXYv\ndZlcH4owuRVEAmrF1itf6bVIqG1fW8LHx8dzS1hE2NvdWWgVZO23tX05tgivjeCwC4g1/zVZDYow\n2Ws80fXKVHrbxYs4emPea71zsYTFHXF8fOy6I2oCHAmyJ7rabWATSCIh1uJbckdYC5tcH4ow2Vsi\nAY6aCKI9emP2tdFYv993fcLWHaF30/Cuw8MKok2b1tarFeDIIhZrWLshWooNkdWhCJO9xxNgK5p2\niyBdIN0b1+9hrWY91u/355ZwyR0RRRzUXBKeCFv3gRZhLcC60Lu1hm3NZGthU4jXB0WY7DWeJeyJ\npheqFY15lnLU+v0+7t69O2/Rwpy3tdAyPmHPAtZivIwlLCJshdz6mcl6oAiTvSdySVixlISF2tET\n4siF0e/3cXx8PG+1ELXrRkdYEda7fyzjEy75mCnA64UiTPaWmvh6gqn3gNOVxfR55KKwW8/Le4rw\nHh0dLbgj5PNK7oganj9YW8CeAJeEWIrO22gLLwKDrAeKMNlrrBB7EQ9aMGu7J2tfrhbjUn80Gl1p\nXojaqmiB9ARYC7GNgPCE2Nv3zjsn64EiTPYeT4ij7eK15StiaY9ixVqfcXSuRdxa1jZZQ+YbpUnr\n88gdUXNFlDLmJEHDE1kK72agCJOtIkrT1ectmWoppQU3g7VS7TGygK34rmIJe24M+RHwrsGKXek8\nchV44WpehENUVN5CAd4cFGGyFdTqM0i/NUlCRzy0FK+xFqp1Q+ixyCcc+YUjAfaqki0jdp67wEvc\n8Oo+lFr0OWQzUITJ1lCry1AKM/PidL0Qs6hFm17aBTrtQqhFSNgFOi3E9kdj2UW5VgGutdbPIZuD\nIkw6p1TPwZ5HGWzWyvQE2G50WQpLK42JCLe0yFrW9SJWiYoA4gI+ra4IWsDbAUWYbA1exTLrbmjx\n81o3Q6vQegLtjeuMuZasuSiOeBVLOBLG2kKdF+vrRT3UPoesH4ow2QpKRXZsenGLcHq7CFuXgj2v\n+Y210LfWjvAKAK1iCUeWamvtiGWEmAJ8s1CEyVbg+X89YdOi6PlrS77c0rjOhKvVjej1es2Lg54g\n27GaEJdcBetwSej3ITcPRZh0jo2CKFmUNuzLhpF5oWZe5IM96sU2L9JB960bodYvibONjrC0COM6\nfMKkOyjCZCtojYKwmW1RNpqN7fUE2oadeenM3phdOIyaXFdpodE+v4WSFezVEvZig1kbeHugCJOt\nwlqJ3oKcTS8ejUbz2gxSHEeOUQKGbVqErR/X/hho63WZY2nMoyVioRSqVqqE5iVqUIi7gSJMtoKa\nJaxdAtodIYIrhXH0UVvG1jq2fV3DobbYVrNaVw05q+Flyun+MvHBkUuCQnzzUITJtYgEp2b56X60\n+OW14XB4pSKZ7WuLOPITezWCIyvc8+m2EoV9RWFhpYU2OzaZTHB6ejqvfuadS3vw4AEePnyIx48f\n4+TkBOPxeP5cvY8cuXkowmRptPB6/VLyhY3/TSmFNR28MRFh7XLw3BB69wqvaI68p2ft2oW3Vfy2\nllI42CqW7Pn5eSi8+lz6Dx48wPPPP4+HDx/i0aNHODk5oQhvCRRhshStPs8Wq1JaLZ1Yn0eLcV6L\nMt9KdRyiSAd7/ctQs2j1mC4/WWtaZD3h1f2HDx/O2+PHj/H48WOMx+Nq5TSyeSjCZGk8t4IXZuYl\nJ3hjXgZb1C/5d71qZ1bUozoOuqKZtYLlulbFiq0XwSD9qAC7V4qyJsJ67NGjR3j06BEeP358xRIW\nEeauGd1AESYrUwrPai1wc3h4WEyk8FwKUaWzSIBLPubWsDO53lVpyWq7uLhw932LmhXb0vHk5GTe\ntF9Y3BHT6ZTuiI5YSoRTSt8C4CsB/EkAJwB+CcA355w/oJ4zBPAWAF8NYAjgGQBvzDn/4bomTboh\nEihPwGwhnVImWklIvfNlq52VfgC8Gg4lIV4FK8BadO1OGN6imm3aCpYWia/0x+PxfDFO+nRHbAfL\nWsKvAvDdAP7j5Wu/A8DPppQ+L+d8cvmctwL4KwD+KoDnAXwvgJ+4fC3ZA2qLbtoS9lwB2i+r/bwt\noWSlgjz2aAvtlFwjNvZ3XQIseELsbUVkxVMLbdSi19h+tJCn3RHk5llKhHPOr9XnKaU3APhDAE8D\neHdK6T6Arwfw13PO77p8ztcB+P9SSl+cc37PWmZNOqMWASFHr6Rk5OuNMt6ixbbWOsGlojpe09fl\n9VellERhtyDSQqktVttqYmzPS/vK6egIWsM3z3V9wk8CyAA+cXn+9OV7/rw8Ief8/pTShwG8EgBF\neA/wFuF0RIT0tfshqt8wGAzmYWU2xMw7Wj9v1Bd3g/cDER3ttXnXuyotAiwCKQKs/bjiw9XnJQG2\n4zriIurTEu6GlUU4zf5FvhXAu3POv3k5/BIAk5zz8+bpz10+RvYEzxK2FqdX68FrNsmi1Gx4Wakf\nRTnUFt2s2K4zPljEOBJgbQXrhTTbrAjXWqmmhE1fJjfLdSzhtwH4fABfsqa5kC2ntnAV1XooFd0Z\nDoduyrE3JiJcKq6jWy2+dx2+3la8hTkrxFaEx+PxPKTMhpg9evRoKRFuydYj3bCSCKeUvgfAawG8\nKuf8EfXQswAGKaX7xhp+6vIx0iGR6JQsP91v3dLn8PBwYTEt8vV6xXe81GO71bxXXS0qtNNKLb1Y\n972Mt+jchp15PlkZl3hebfHqc93XlnAUG6zfm2wvS4vwpQB/OYAvzTl/2Dz8XgBTAK8B8G8vn/+5\nAP44gF++3lTJskRiGvk7Pb+o7rfUdhDLdJmIh6gcpY731SnGUYbbdRfSonRib6wl8cLG/mph9Npk\nMlmI47V97RvWiRYitNa/S+t2N1g2TvhtAF4P4HUAHqWUnrp86NM553HO+fmU0g8AeEtK6ZMAHgD4\nZwB+kZERN0u00BQJbUsrRSLYiIXI/yuVz/QCnc1004/bOg82rtcKsb62VbBpxVGasQ0xi8LOzs/P\nXRH2+jqeV8Q26kvEg7xWi7D19ZLtZllL+Bswi4Z4pxn/OgA/fNn/JgDnAP4NZska7wDwjatPkayK\nJ7T6HEAY5+vFALfu11bbxaLlaAvuLJNcsSpeKJnXt5EF+uiNaZHVfe+ow890coUd88LOtCVsLXmy\nvSwbJ1x1suWcTwH8rctGOqAWDVCK8S31axlt9rHanm5aZGtHr9ykZwmvQ4RrqcUirlYAPVG0QmuF\n2DtvrQdh60loS5xW8O7A2hF7zDLCG4mbjnawxXKWqWAWWcytuxxrn7AX47tuf7B1M+ijtW5L7gUr\ntq0pydF7WRdEZJVTiHcHivAeEwlvFFJW64v12hLPawVWn0dWro339eJ/IzeEV3ZyWWpZbdrHu6zV\n6p174zpczTt6rgc7T8b+7hYU4T3FuiOiwuo24qAU+qVDyiSWN2otacU6vbhW8lLH/pbadYjqO1hL\nUy+ieb5aL624pfaviHCU1RZZu3YxjlbwbkER3kNKERCey2GZ2F8twsfHx2HzdsWIdswo1XPwXCWt\nYXWr4AlxqZavF8Fgz6PCOt6x5AaxR71Y6B1pCe8GFOE9pVWArQjrKATb90T47t27bvNqOUTlLFtc\nDCW/b9RfhlqRHa++g04vtvG8di+31oI7JVGNRLYUz0wR3n4owntMaVEuEuBSTYZIhO/du7fQ7t69\nu2Dl1ny+1nq1QroOkW2hVN/BuiJsjQevvoPewaK1JKWXlafnpsdsvzRGtheK8A5QCjnzxkplG+1Y\n66JYr9ebC+zdu3fnbgdd50FXPPOKp0eF1ZcR1pb0Yn0eiZh9XCdVtOxo4YluqdBOqcykdkfUrpns\nHxThLaFm/bX6TL3IhtJYSzUyaWL5at/vnTt3FsLS7EKbN691+W11vyW9uHT0ajpEacanp6dXUok9\nl4T2B0cpxrVFNArw/kMR3gJKfk4RrJrP1p6XIh4iP7AVXyvCUSSE3l7e20AzimpYlUhoo7oOpYUt\nL/bXE2B9bguu20U5m16sY32jpAq6FW4vFOGO8Vb35Sh9ETMvssAevbKOXgSELjcZHW1fuxtspbNl\ni+3oa10GW6GsVDwnCjHzCpqXEi2iGg+18DS9h5u3k0Wp0A4F+PZAEd4CSmFX4orwtgnystC8uNta\nKwmxPtbKUmoRbg0zW4Vl0ou9JIeoX6vtUEsv9o7WBdGSYkwBvl1QhDvEiwqIRFjEsFSvQYTQc1XU\nxloW0rxiO3Ys2tvNCzdbFetyiKqY2doNNVdDraZDqQhPSbyjhAvrjqD43k4owltALQtMuyPs7hR2\nf7bhcBiKaG2s9txa+rF2l2yyxkMUz6stTJte3JI2XKrzYMXWFuvxzqXvpRaz7i8RKMJbREmExS+r\nRdjbAmg0GlX9u3astsjnLdKVEjF6vV5T4sWqRFltXgnJUlyu9t8uW2THlq30mrV4o/RiCvHthiLc\nMcvE/OqC6bIopkPF7t69OxfhUryvJ8olt4X3nNriXynTbZ1CHO1abHcurrWSENvHxLotWbi6eQuH\ndowifHuhCHdI5A+21qPnExZL2KYO37lzp2ihekLc6je28cpe/LKet77G67ggNNGinBZiu9Bmdy/2\nmrWIS66LVuvW8/lGjdxeKMJbgGclWpETF0Akwvfu3cP9+/dxfHwcugw8F8IyFm9NWEtCu85046ja\nWW37+FJmm4STtVQ7Ozs7q8YqRyIbZfaR2wtFeEla6hq0HLXAlixKqeNbqlhmW8ny9er3tlZSW4Zl\nxMVLI46OUUF1b0y2jJdMtlJqcc0lYctNljL17DURUoIi3EAphtcTVrsQ5UUKLNMGg8GCy8HWcJCF\nOYnX9fzA3mJcLaFindarxrMGvVRib2yZnSpqLgiv3KSNdPDSiz3rlnG+ZFUowo1EZRUjcbUCp4Wu\nNOY93u/33boNtoiOFeGWRTb7mZFP97qUssKiZAvvvJQoYceiVGKvlQQ4Sqyg+JJ1QBGuEEUreBZu\nS6yt7ZdqPEh/MBiEdRusJTwajZrdCy1JFfIdXIeSH1RbvFb0vPTiUthZVLu3JcXYhp5F6cUl10np\nmgmJoAg3YAU4ahJG5vlfbb9VJOU9vX3cdAlJ7Y5oKd7jWb/rzmwD6qUnddZbKeZWmrcVvHYp2OMy\n6cVR7G9kBZeOhLRCEW7Ai9n1XAi2voPXl/Nl4nT7/b6bIWebbLDpuTi8H4zIot+EX7gkVl6IWamW\nb6ubwcuEi/pRYR9bea0U8UABJqtAEW7EE2JPPKWGgm7emK16VjpKgkatjUYj9Pv95lheK7absoJb\njuKOqG0VL7V89aJb1Nd+3kjcrevBq0Hhxfzq+Zf6hNSgCFfwXBGR1apFV0SxVGinJbNNLGEr4l4b\nDofo9/tNkRqR6EZtXXiLWp4lbH2/OubXFk+PiqqLhdvSlk268K7J9glpgSLcQCTEVjxFLCN3gS39\n2BrLq90c1q1hx7y6DTVxjc7XgSe6Xl8sYS/Rwu5qrAXXxvvqvlQwi9wMUXpx7aivy7tWQpaBItyA\nvWX3Fs50SrHeEDNqYrVGC3jRol5LGnIU11wa09caPbYqUUytFmBbXF1HMGi/b5Rw8ejRoyvnZ2dn\n4U4a3rmXeLFM9hshq0ARrqDFyC7KeZaqTiuWCAavif9Wv9ZavFqAlwk584SzlOnXMn5dogQHnX7s\nWcJ6PzcrstKicxHhKPHDHvXcan1C1gVFuIHIJ2xFU1vB2hK2Mb3Hx8dVEdb9KLHC65dENBIRG6nQ\n8poaNvMtyoTLOS/4eT23gh3TQqsF2FrHZ2dn87m0WreE3DQU4QasK8JavuKbbYlg0K3mbmhJK44W\nz0ohYaXb7mh8WaEqbTtkWxTdEI159R7EjaH9u+u6FkI2CUW4gucL9lwQ2g3RctQiHEVFlLLaIrcD\nEIusN9a6GLXsbXmtxq5urTV/tW9YxwbrbLeozoMX0UAxJtsARbgBLz7YE+BS/K53bElrLlnBpaSK\nyA3g+WKjZq1Xj0jIol0nvLFa+rGXaqwTMsQalveLBJjCS7YRinAFL0lDW8JeXLBn9Xqtta6D+HqX\nyWhrsXJtPV67S4R9rMWnLHh7rUX91tTiqFBP5I6IBJiLbWSboAg34BXo8SIilnVH1Go6aCGuJVcA\nL0Q2eALsJR7YojleX48JLTGy0c7Dy+xuXDu3OydH7gg9P0+ICekSinADniW8jDsialE9h6iqWS3D\nzeIJsHUxtGaUTafTK+/tfZ7g7UgR7VhRqhVRSzX2yk+yxgPZJSjCFbzICJsht6wVPBqNFgrtWFdD\nVFBHz6fFFWF9v7YegiRHeKJmx2Q3Cfs53mcDaCo1KedaQPXnRefezsq2/m+L+4FiTLYBinADJUvY\nCnFrExG2otricmjJaosW37xavfa2Xjc9rt/b6+vzZaqdRcIauUWiQjtesZ3aPAnpGopwhVqIWkto\nmtcGg0EorKU6Di19LxIiKpZeq1qmH5P31p+j0edRzK/XShXMoopmns/b9im8ZBegCDfguSS0CNeE\nOObWQ8oAAAmRSURBVLKE9ft7fe88GrPULOFoZ+LS9kH6vWv9UnEdO663kPcEtVRKstYnZNuhCK9I\nzScrx8gnq6MN1knO2Y3Jjfq1ELBWEbZjtS3mdbMF062l6yWMELIvUIQbEOHUVuN4PF6IZpDnaevS\nVgGTOgd37txBv9/fyFzF9VALPZN+687F4o6Qz6j1bdqxTS/WLgjPfcIFNHJboAhXECtMi/Dp6enc\nP6xjc0WEbSnGk5OTK9sSbVqEvWb9rDoawou7tWPy/vbzvH5pqyErwKWQMgow2XcowhX07bCIVkmA\n9W38eDwu1o3YFN5iVosQ17YBkmu13493Hu2IrNOLWy1hQvYZinAFawlPJpOFuF39uFjAw+FwLsB2\nnzm9tdGm5xslaei+F4MbxebK+9vP8+Yg34Vd6NPpxVGhHYoxuU1QhBvQIqx9wFaAJ5MJBoMBxuPx\nvLylt+vyYDDA4eHhRubqhW6VWrRo5x0jQfTGS64N/Vl20Y1uCXLbWEqEU0rfAuArAfxJACcAfgnA\nN+ecP6Ce804Af0G9LAP4vpzzG6892w6wlnBkAYvAeFsUeUcR8k1Qi5/Vx9Zyk6sW8LFWdckSlvfy\nIi4I2VeWtYRfBeC7AfzHy9d+B4CfTSl9Xs755PI5GcC/APD3AUgM1+M1zLUTtFh5PmAdMeFtVx9t\nZb9JEbZhXd7ilxXimtuiFlJnBbM1+81avtGRkH1lKRHOOb9Wn6eU3gDgDwE8DeDd6qHHOeePXnt2\nW4AIhIiQFy3hlaDUR69/EyLc0jzXRWRFt3yuENWqiLLf7OsZokZuC9f1CT+JmeX7CTP+NSml/wHA\nswB+GsC3K0t55xAB0gJsq5x5lc9K/U1tqCnzlKNnWXr+10icV1kgiwS+Ju4ti36E7Bsri3Caqchb\nAbw75/yb6qEfAfC7AD4C4AsAfCeAzwHw164xz86wYhJVM6vVfohqQWx67i3nrcdlPztabIsW3wi5\njVzHEn4bgM8H8Of1YM75+9Xpb6SUngXwcymll+acP3iNz+sMrs4TQjbFSo7JlNL3AHgtgFfnnP+g\n8vRfxWyB7uWrfBYhhOwzS1vClwL85QC+NOf84YaXfCFmfuOaWBNCyK1j2TjhtwF4PYDXAXiUUnrq\n8qFP55zHKaWXAfgbAN4O4OMAXgHgLQDelXN+3/qmTQgh+8GylvA3YGbVvtOMfx2AHwYwAfCXAPxt\nAMcAfg/Avwbwj681S0II2VOWjRMu+pBzzr8P4NXXmRAhhNwmNpcxQAghpApFmBBCOoQiTAghHUIR\nJoSQDqEIE0JIh1CECSGkQyjChBDSIRRhQgjpEIowIYR0CEWYEEI6hCJMCCEdQhEmhJAOoQgTQkiH\nUIQJIaRDKMKEENIhFGFCCOkQijAhhHQIRZgQQjqEIkwIIR1CESaEkA6hCBNCSIdsgwiPup4AIYRs\niKq+bYMIf1bXEyCEkA3xWbUnpJzzDcyjMIGUXgTgywB8CMC408kQQsh6GGEmwM/knD9eemLnIkwI\nIbeZbXBHEELIrYUiTAghHUIRJoSQDqEIE0JIh2ylCKeUvjGl9MGU0klK6VdSSn+m6zmtg5TSm1JK\nF6b9ZtfzWoWU0qtSSj+VUvqvl9fxOuc535ZS+khK6XFK6d+nlF7exVxXoXZ9KaUfdP6Wb+9qvq2k\nlL4lpfSelNLzKaXnUkr/NqX0OeY5w5TS96aUPpZSepBS+jcppT/S1ZyXofH63mn+bucppbd1Neet\nE+GU0lcD+C4AbwLwhQD+M4BnUkov7nRi6+N9AJ4C8JLL9iXdTmdljgH8GoA3ArgSYpNS+mYAfxPA\n/wzgiwE8wuzvOLjJSV6D4vVd8jNY/Fu+/mamdi1eBeC7AfxZAH8JQB/Az6aUjtRz3grgvwfwVwH8\nBQB/FMBP3PA8V6Xl+jKAf4EX/nafAeDv3fA81Wxy3qoG4FcA/G/qPAH4fQB/r+u5reHa3gTgP3U9\njw1c1wWA15mxjwD4JnV+H8AJgK/qer5rur4fBPCTXc9tDdf24svr+xL1dzoF8JXqOZ97+Zwv7nq+\n172+y7FfAPCWrucmbass4ZRSH8DTAH5exvLsW/s5AK/sal5r5k9c3uL+Tkrpf08p/XddT2jdpJRe\nipmFof+OzwP4VezP3xEAXn15y/tbKaW3pZT+m64ntAJPYmYZfuLy/GkAPSz+7d4P4MPYzb+dvT7h\na1JKH00p/XpK6X81lvKN0uvqgwNeDOAQwHNm/DnMfo13nV8B8AYA78fsFujNAP5DSulP5ZwfdTiv\ndfMSzP7he3/Hl9z8dDbCz2B2i/5BAJ8N4DsAvD2l9MpLw2HrSSklzFwP7845y9rESwBMLn80NTv3\ntwuuDwB+BMDvYna39gUAvhPA5wD4azc+SWyfCO81Oedn1On7Ukrvwewfw1dhdntLdoSc84+r099I\nKf06gN8B8GrMbnd3gbcB+Hzs7rpEDbm+P68Hc87fr05/I6X0LICfSym9NOf8wZucILB9C3MfA3CO\nmcNc8xSAZ29+Opsl5/xpAB8AsDNRA408i5kv/1b8HQHg8j/vx7Ajf8uU0vcAeC2AV+ecP6IeehbA\nIKV037xkp/525vr+oPL0X8Xs32snf7utEuGc8xmA9wJ4jYxd3lK8BsAvdTWvTZFSuovZrWztH8lO\ncSlIz2Lx73gfsxXrvfs7AkBK6TMBvAg78Le8FKgvB/AXc84fNg+/F8AUi3+7zwXwxwH88o1N8hpU\nrs/jCzFzn3Xyt9tGd8RbAPxQSum9AN4D4JsA3AHwQ11Oah2klP4pgJ/GzAXxxwD8Q8z+wf9Yl/Na\nhZTSMWaWQ7ocellK6RUAPpFz/j3MfHHfmlL6bcwq5H07ZlEu/66D6S5N6fou25sw8wk/e/m8f4LZ\nXc0zV99te7iMh309gNcBeJRSkruVT+ecxznn51NKPwDgLSmlTwJ4AOCfAfjFnPN7upl1O7XrSym9\nDMDfAPB2AB8H8ArMNOddOef3dTHnzsMzgrCSN2L2H/cEs1/fL+p6Tmu6rh/DTIhOMFtt/lEAL+16\nXitey5diFvpzbtq/VM95M2aLH48xE6eXdz3vdVwfZmUK34GZAI8B/BcA/xzAf9v1vBuuy7umcwBf\nq54zxCzW9mOYifC/BvBHup77Oq4PwGcCeCeAj17+u3w/Zouqd7uaM0tZEkJIh2yVT5gQQm4bFGFC\nCOkQijAhhHQIRZgQQjqEIkwIIR1CESaEkA6hCBNCSIdQhAkhpEMowoQQ0iEUYUII6RCKMCGEdAhF\nmBBCOuT/B9+JhslGGpkQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f01bc906610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import pylab as plt\n",
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.show()\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "num_classes = Y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple 2- layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for the number of neurons in the hidden unit\n",
    "M = 300\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(M, input_dim=num_pixels, init='normal', activation='relu'))\n",
    "model1.add(Dense(10, activation='softmax'))\n",
    "model1.compile(optimizer='adam',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "9.99999974738e-05\n"
     ]
    }
   ],
   "source": [
    "# default learning rate\n",
    "print(model1.optimizer.lr.get_value())\n",
    "model1.optimizer.lr.set_value(0.0001)  # [1, 0.1, 0.01, 0.001, 0.0001, 0.00001] #recompile first!\n",
    "print(model1.optimizer.lr.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "6s - loss: 0.9650 - acc: 0.7702 - val_loss: 0.4564 - val_acc: 0.8939\n",
      "Baseline Error: 10.61%\n"
     ]
    }
   ],
   "source": [
    "model1.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=1, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model1.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(lr=0.001, M=300):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(M, input_dim=num_pixels, init='normal', activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "    model.optimizer.lr.set_value(lr)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_31 (Dense)                 (None, 2000)          1570000     dense_input_16[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_32 (Dense)                 (None, 10)            20010       dense_31[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 1590010\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = get_model(lr=.01, M=2000) # [10, 50, 100, 300, 1000, 2000] #\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "37s - loss: 0.4591 - acc: 0.9167 - val_loss: 0.1272 - val_acc: 0.9621\n",
      "Epoch 2/10\n",
      "36s - loss: 0.0963 - acc: 0.9705 - val_loss: 0.0911 - val_acc: 0.9731\n",
      "Epoch 3/10\n",
      "50s - loss: 0.0771 - acc: 0.9758 - val_loss: 0.1057 - val_acc: 0.9697\n",
      "Epoch 4/10\n",
      "51s - loss: 0.0664 - acc: 0.9800 - val_loss: 0.1131 - val_acc: 0.9715\n",
      "Epoch 5/10\n",
      "51s - loss: 0.0593 - acc: 0.9828 - val_loss: 0.1142 - val_acc: 0.9713\n",
      "Epoch 6/10\n",
      "51s - loss: 0.0578 - acc: 0.9834 - val_loss: 0.1331 - val_acc: 0.9682\n",
      "Epoch 7/10\n",
      "52s - loss: 0.0513 - acc: 0.9856 - val_loss: 0.1422 - val_acc: 0.9719\n",
      "Epoch 8/10\n",
      "55s - loss: 0.0529 - acc: 0.9861 - val_loss: 0.1299 - val_acc: 0.9738\n",
      "Epoch 9/10\n",
      "58s - loss: 0.0479 - acc: 0.9873 - val_loss: 0.1465 - val_acc: 0.9726\n",
      "Epoch 10/10\n",
      "58s - loss: 0.0476 - acc: 0.9877 - val_loss: 0.1522 - val_acc: 0.9726\n",
      "Baseline Error: 2.74%\n"
     ]
    }
   ],
   "source": [
    "model2.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model2.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_reg_model(lr=0.001, M=300, w=0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(M, input_dim=num_pixels, init='normal', activation='relu', W_regularizer=l2(w)))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "    model.optimizer.lr.set_value(lr)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_54 (Dense)                 (None, 300)           235500      dense_input_27[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_55 (Dense)                 (None, 10)            3010        dense_54[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 238510\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model0 = get_reg_model(lr=.01, M=300, w=0)\n",
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6s - loss: 0.2118 - acc: 0.9351 - val_loss: 0.1296 - val_acc: 0.9583\n",
      "Epoch 2/10\n",
      "6s - loss: 0.0949 - acc: 0.9706 - val_loss: 0.1004 - val_acc: 0.9706\n",
      "Epoch 3/10\n",
      "6s - loss: 0.0690 - acc: 0.9785 - val_loss: 0.1068 - val_acc: 0.9716\n",
      "Epoch 4/10\n",
      "7s - loss: 0.0656 - acc: 0.9803 - val_loss: 0.0999 - val_acc: 0.9732\n",
      "Epoch 5/10\n",
      "7s - loss: 0.0501 - acc: 0.9847 - val_loss: 0.0948 - val_acc: 0.9756\n",
      "Epoch 6/10\n",
      "6s - loss: 0.0514 - acc: 0.9838 - val_loss: 0.1550 - val_acc: 0.9687\n",
      "Epoch 7/10\n",
      "7s - loss: 0.0548 - acc: 0.9837 - val_loss: 0.1469 - val_acc: 0.9693\n",
      "Epoch 8/10\n",
      "7s - loss: 0.0506 - acc: 0.9861 - val_loss: 0.1429 - val_acc: 0.9747\n",
      "Epoch 9/10\n",
      "7s - loss: 0.0397 - acc: 0.9883 - val_loss: 0.1271 - val_acc: 0.9746\n",
      "Epoch 10/10\n",
      "7s - loss: 0.0392 - acc: 0.9888 - val_loss: 0.1282 - val_acc: 0.9766\n",
      "Baseline Error: 2.34%\n"
     ]
    }
   ],
   "source": [
    "model0.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=10, batch_size=200, verbose=2)\n",
    "scores = model0.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "7s - loss: 0.0140 - acc: 0.9955 - val_loss: 0.1142 - val_acc: 0.9798\n",
      "Epoch 2/10\n",
      "8s - loss: 0.0053 - acc: 0.9984 - val_loss: 0.1118 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "7s - loss: 0.0033 - acc: 0.9992 - val_loss: 0.1106 - val_acc: 0.9803\n",
      "Epoch 4/10\n",
      "7s - loss: 0.0024 - acc: 0.9996 - val_loss: 0.1114 - val_acc: 0.9799\n",
      "Epoch 5/10\n",
      "7s - loss: 0.0018 - acc: 0.9997 - val_loss: 0.1114 - val_acc: 0.9804\n",
      "Epoch 6/10\n",
      "7s - loss: 0.0015 - acc: 0.9998 - val_loss: 0.1125 - val_acc: 0.9803\n",
      "Epoch 7/10\n",
      "7s - loss: 0.0012 - acc: 0.9999 - val_loss: 0.1123 - val_acc: 0.9806\n",
      "Epoch 8/10\n",
      "7s - loss: 0.0010 - acc: 0.9999 - val_loss: 0.1134 - val_acc: 0.9807\n",
      "Epoch 9/10\n",
      "7s - loss: 9.1122e-04 - acc: 0.9999 - val_loss: 0.1131 - val_acc: 0.9808\n",
      "Epoch 10/10\n",
      "7s - loss: 8.0099e-04 - acc: 1.0000 - val_loss: 0.1138 - val_acc: 0.9806\n",
      "Baseline Error: 1.94%\n"
     ]
    }
   ],
   "source": [
    "model0.optimizer.lr.set_value(0.001)\n",
    "model0.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=10, batch_size=200, verbose=2)\n",
    "scores = model0.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_56 (Dense)                 (None, 300)           235500      dense_input_28[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_57 (Dense)                 (None, 10)            3010        dense_56[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 238510\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model0 = get_reg_model(lr=.01, M=300, w=0.002)\n",
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "4s - loss: 0.5470 - acc: 0.9119 - val_loss: 0.2027 - val_acc: 0.9386\n",
      "Epoch 2/30\n",
      "4s - loss: 0.4045 - acc: 0.9355 - val_loss: 0.1701 - val_acc: 0.9489\n",
      "Epoch 3/30\n",
      "5s - loss: 0.3698 - acc: 0.9390 - val_loss: 0.1800 - val_acc: 0.9458\n",
      "Epoch 4/30\n",
      "5s - loss: 0.3562 - acc: 0.9416 - val_loss: 0.2346 - val_acc: 0.9275\n",
      "Epoch 5/30\n",
      "6s - loss: 0.3324 - acc: 0.9449 - val_loss: 0.1978 - val_acc: 0.9391\n",
      "Epoch 6/30\n",
      "23s - loss: 0.3350 - acc: 0.9431 - val_loss: 0.1577 - val_acc: 0.9528\n",
      "Epoch 7/30\n",
      "41s - loss: 0.3138 - acc: 0.9463 - val_loss: 0.1739 - val_acc: 0.9461\n",
      "Epoch 8/30\n",
      "51s - loss: 0.3173 - acc: 0.9461 - val_loss: 0.1710 - val_acc: 0.9479\n",
      "Epoch 9/30\n",
      "55s - loss: 0.3150 - acc: 0.9457 - val_loss: 0.1845 - val_acc: 0.9421\n",
      "Epoch 10/30\n",
      "58s - loss: 0.3174 - acc: 0.9444 - val_loss: 0.1567 - val_acc: 0.9529\n",
      "Epoch 11/30\n",
      "60s - loss: 0.3033 - acc: 0.9465 - val_loss: 0.1498 - val_acc: 0.9517\n",
      "Epoch 12/30\n",
      "62s - loss: 0.3121 - acc: 0.9445 - val_loss: 0.1980 - val_acc: 0.9381\n",
      "Epoch 13/30\n",
      "62s - loss: 0.3090 - acc: 0.9474 - val_loss: 0.1657 - val_acc: 0.9495\n",
      "Epoch 14/30\n",
      "63s - loss: 0.3033 - acc: 0.9462 - val_loss: 0.1882 - val_acc: 0.9453\n",
      "Epoch 15/30\n",
      "62s - loss: 0.3042 - acc: 0.9469 - val_loss: 0.1429 - val_acc: 0.9567\n",
      "Epoch 16/30\n",
      "62s - loss: 0.3103 - acc: 0.9446 - val_loss: 0.1823 - val_acc: 0.9431\n",
      "Epoch 17/30\n",
      "63s - loss: 0.2982 - acc: 0.9486 - val_loss: 0.1621 - val_acc: 0.9494\n",
      "Epoch 18/30\n",
      "63s - loss: 0.2973 - acc: 0.9476 - val_loss: 0.1747 - val_acc: 0.9458\n",
      "Epoch 19/30\n",
      "62s - loss: 0.3046 - acc: 0.9458 - val_loss: 0.1760 - val_acc: 0.9441\n",
      "Epoch 20/30\n",
      "62s - loss: 0.3022 - acc: 0.9466 - val_loss: 0.1787 - val_acc: 0.9437\n",
      "Epoch 21/30\n",
      "62s - loss: 0.3067 - acc: 0.9463 - val_loss: 0.1601 - val_acc: 0.9546\n",
      "Epoch 22/30\n",
      "63s - loss: 0.2998 - acc: 0.9470 - val_loss: 0.1443 - val_acc: 0.9561\n",
      "Epoch 23/30\n",
      "63s - loss: 0.2927 - acc: 0.9477 - val_loss: 0.1563 - val_acc: 0.9497\n",
      "Epoch 24/30\n",
      "62s - loss: 0.3034 - acc: 0.9454 - val_loss: 0.1802 - val_acc: 0.9427\n",
      "Epoch 25/30\n",
      "61s - loss: 0.2960 - acc: 0.9482 - val_loss: 0.1546 - val_acc: 0.9518\n",
      "Epoch 26/30\n",
      "61s - loss: 0.2892 - acc: 0.9482 - val_loss: 0.1813 - val_acc: 0.9453\n",
      "Epoch 27/30\n",
      "62s - loss: 0.2983 - acc: 0.9468 - val_loss: 0.1372 - val_acc: 0.9601\n",
      "Epoch 28/30\n",
      "61s - loss: 0.2956 - acc: 0.9484 - val_loss: 0.1591 - val_acc: 0.9511\n",
      "Epoch 29/30\n",
      "61s - loss: 0.2985 - acc: 0.9480 - val_loss: 0.1664 - val_acc: 0.9489\n",
      "Epoch 30/30\n",
      "61s - loss: 0.2979 - acc: 0.9477 - val_loss: 0.1739 - val_acc: 0.9433\n",
      "Baseline Error: 5.67%\n"
     ]
    }
   ],
   "source": [
    "model0.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=30, batch_size=200, verbose=2)\n",
    "scores = model0.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dropout_model(lr=0.001, M=300, w=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(M, input_dim=num_pixels, init='normal', activation='relu'))\n",
    "    model.add(Dropout(w))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "    model.optimizer.lr.set_value(lr)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_82 (Dense)                 (None, 300)           235500      dense_input_41[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)             (None, 300)           0           dense_82[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_83 (Dense)                 (None, 10)            3010        dropout_22[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 238510\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_dropout_model(lr=.001, M=300, w=1) # w = [0, 0.1, 0.25, 0.5, 0.75, 0.9, 1]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "6s - loss: 0.3500 - acc: 0.9031 - val_loss: 0.1803 - val_acc: 0.9469\n",
      "Epoch 2/30\n",
      "6s - loss: 0.1464 - acc: 0.9581 - val_loss: 0.1205 - val_acc: 0.9633\n",
      "Epoch 3/30\n",
      "6s - loss: 0.0996 - acc: 0.9717 - val_loss: 0.0948 - val_acc: 0.9715\n",
      "Epoch 4/30\n",
      "6s - loss: 0.0743 - acc: 0.9786 - val_loss: 0.0905 - val_acc: 0.9721\n",
      "Epoch 5/30\n",
      "7s - loss: 0.0572 - acc: 0.9838 - val_loss: 0.0803 - val_acc: 0.9752\n",
      "Epoch 6/30\n",
      "6s - loss: 0.0466 - acc: 0.9871 - val_loss: 0.0762 - val_acc: 0.9760\n",
      "Epoch 7/30\n",
      "6s - loss: 0.0375 - acc: 0.9893 - val_loss: 0.0681 - val_acc: 0.9778\n",
      "Epoch 8/30\n",
      "6s - loss: 0.0302 - acc: 0.9918 - val_loss: 0.0692 - val_acc: 0.9788\n",
      "Epoch 9/30\n",
      "6s - loss: 0.0240 - acc: 0.9941 - val_loss: 0.0642 - val_acc: 0.9795\n",
      "Epoch 10/30\n",
      "5s - loss: 0.0192 - acc: 0.9957 - val_loss: 0.0616 - val_acc: 0.9805\n",
      "Epoch 11/30\n",
      "6s - loss: 0.0155 - acc: 0.9971 - val_loss: 0.0674 - val_acc: 0.9786\n",
      "Epoch 12/30\n",
      "5s - loss: 0.0127 - acc: 0.9976 - val_loss: 0.0664 - val_acc: 0.9799\n",
      "Epoch 13/30\n",
      "6s - loss: 0.0100 - acc: 0.9983 - val_loss: 0.0641 - val_acc: 0.9807\n",
      "Epoch 14/30\n",
      "7s - loss: 0.0083 - acc: 0.9988 - val_loss: 0.0612 - val_acc: 0.9816\n",
      "Epoch 15/30\n",
      "6s - loss: 0.0066 - acc: 0.9992 - val_loss: 0.0696 - val_acc: 0.9796\n",
      "Epoch 16/30\n",
      "6s - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0675 - val_acc: 0.9807\n",
      "Epoch 17/30\n",
      "6s - loss: 0.0050 - acc: 0.9995 - val_loss: 0.0722 - val_acc: 0.9802\n",
      "Epoch 18/30\n",
      "6s - loss: 0.0030 - acc: 0.9999 - val_loss: 0.0661 - val_acc: 0.9806\n",
      "Epoch 19/30\n",
      "7s - loss: 0.0027 - acc: 0.9999 - val_loss: 0.0670 - val_acc: 0.9814\n",
      "Epoch 20/30\n",
      "7s - loss: 0.0022 - acc: 0.9998 - val_loss: 0.0681 - val_acc: 0.9801\n",
      "Epoch 21/30\n",
      "7s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0672 - val_acc: 0.9813\n",
      "Epoch 22/30\n",
      "7s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0705 - val_acc: 0.9808\n",
      "Epoch 23/30\n",
      "7s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0702 - val_acc: 0.9807\n",
      "Epoch 24/30\n",
      "7s - loss: 8.7924e-04 - acc: 1.0000 - val_loss: 0.0737 - val_acc: 0.9814\n",
      "Epoch 25/30\n",
      "6s - loss: 7.4186e-04 - acc: 1.0000 - val_loss: 0.0711 - val_acc: 0.9812\n",
      "Epoch 26/30\n",
      "6s - loss: 0.0150 - acc: 0.9953 - val_loss: 0.0881 - val_acc: 0.9795\n",
      "Epoch 27/30\n",
      "6s - loss: 0.0102 - acc: 0.9968 - val_loss: 0.0806 - val_acc: 0.9813\n",
      "Epoch 28/30\n",
      "6s - loss: 0.0019 - acc: 0.9998 - val_loss: 0.0743 - val_acc: 0.9820\n",
      "Epoch 29/30\n",
      "7s - loss: 6.6964e-04 - acc: 1.0000 - val_loss: 0.0767 - val_acc: 0.9816\n",
      "Epoch 30/30\n",
      "7s - loss: 4.8014e-04 - acc: 1.0000 - val_loss: 0.0762 - val_acc: 0.9825\n",
      "Baseline Error: 1.75%\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=30, batch_size=200, verbose=2)\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3-layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_3nn_model(lr=0.001, M1=300, w1=0.2, M2=240, w2=0.2, reg=0.002):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(M1, input_dim=num_pixels, init='normal', activation='relu'))\n",
    "    model.add(Dropout(w1))\n",
    "    model.add(Dense(M2, input_dim=num_pixels, activation='relu', W_regularizer=l2(reg)))\n",
    "    model.add(Dropout(w2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "    model.optimizer.lr.set_value(lr)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_84 (Dense)                 (None, 500)           392500      dense_input_42[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)             (None, 500)           0           dense_84[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_85 (Dense)                 (None, 500)           250500      dropout_23[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)             (None, 500)           0           dense_85[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_86 (Dense)                 (None, 10)            5010        dropout_24[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 648010\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_3nn_model(lr=.001, M1=500, w1=0.4, M2=500, w2=0.4, reg=0.002)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "20s - loss: 0.7975 - acc: 0.8933 - val_loss: 0.1392 - val_acc: 0.9582\n",
      "Epoch 2/10\n",
      "18s - loss: 0.2771 - acc: 0.9518 - val_loss: 0.1064 - val_acc: 0.9658\n",
      "Epoch 3/10\n",
      "19s - loss: 0.1991 - acc: 0.9606 - val_loss: 0.0927 - val_acc: 0.9718\n",
      "Epoch 4/10\n",
      "19s - loss: 0.1704 - acc: 0.9674 - val_loss: 0.0898 - val_acc: 0.9724\n",
      "Epoch 5/10\n",
      "20s - loss: 0.1603 - acc: 0.9700 - val_loss: 0.0762 - val_acc: 0.9770\n",
      "Epoch 6/10\n",
      "21s - loss: 0.1484 - acc: 0.9726 - val_loss: 0.0814 - val_acc: 0.9741\n",
      "Epoch 7/10\n",
      "22s - loss: 0.1409 - acc: 0.9753 - val_loss: 0.0678 - val_acc: 0.9793\n",
      "Epoch 8/10\n",
      "23s - loss: 0.1320 - acc: 0.9777 - val_loss: 0.0708 - val_acc: 0.9791\n",
      "Epoch 9/10\n",
      "23s - loss: 0.1288 - acc: 0.9772 - val_loss: 0.0701 - val_acc: 0.9785\n",
      "Epoch 10/10\n",
      "24s - loss: 0.1217 - acc: 0.9793 - val_loss: 0.0701 - val_acc: 0.9784\n",
      "Baseline Error: 2.16%\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=10, batch_size=200, verbose=2)\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr.set_value(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "24s - loss: 0.0952 - acc: 0.9870 - val_loss: 0.0553 - val_acc: 0.9830\n",
      "Epoch 2/10\n",
      "23s - loss: 0.0793 - acc: 0.9892 - val_loss: 0.0532 - val_acc: 0.9833\n",
      "Epoch 3/10\n",
      "23s - loss: 0.0719 - acc: 0.9895 - val_loss: 0.0525 - val_acc: 0.9834\n",
      "Epoch 4/10\n",
      "24s - loss: 0.0654 - acc: 0.9898 - val_loss: 0.0529 - val_acc: 0.9836\n",
      "Epoch 5/10\n",
      "23s - loss: 0.0612 - acc: 0.9902 - val_loss: 0.0518 - val_acc: 0.9841\n",
      "Epoch 6/10\n",
      "27s - loss: 0.0591 - acc: 0.9898 - val_loss: 0.0521 - val_acc: 0.9839\n",
      "Epoch 7/10\n",
      "28s - loss: 0.0565 - acc: 0.9903 - val_loss: 0.0526 - val_acc: 0.9835\n",
      "Epoch 8/10\n",
      "27s - loss: 0.0546 - acc: 0.9905 - val_loss: 0.0519 - val_acc: 0.9841\n",
      "Epoch 9/10\n",
      "28s - loss: 0.0537 - acc: 0.9904 - val_loss: 0.0534 - val_acc: 0.9841\n",
      "Epoch 10/10\n",
      "28s - loss: 0.0538 - acc: 0.9905 - val_loss: 0.0524 - val_acc: 0.9831\n",
      "Baseline Error: 1.69%\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=10, batch_size=200, verbose=2)\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
